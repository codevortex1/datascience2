{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a651121",
   "metadata": {},
   "source": [
    "## Documentation\n",
    "https://spark.apache.org/docs/latest/sql-data-sources-json.html\n",
    "\n",
    "### Reading the JSON using spark sql\n",
    "spark.sql(\"CREATE OR REPLACE TEMPORARY VIEW BABYNAME USING json OPTIONS\" + \n",
    "      \" (path '/data/informatica/shared/babynames/Baby.json',multiline true)\")\n",
    "spark.sql(\"select data,meta.view.id from BABYNAME\").show()\n",
    "\n",
    "### Print the schema\n",
    "baby.printSchema()\n",
    "\n",
    "val babydf2 = spark.sql(\"SELECT data FROM babyname\")\n",
    "babydf2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3195282",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spark.implicits._\n",
    "\n",
    "val path = \"/data/informatica/shared/babynames/Baby.json\"\n",
    "val baby = spark.read.option(\"multiline\",\"true\").json(path)\n",
    "//baby.createOrReplaceTempView(\"babyname1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5a57f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val babyname2 = baby.select( explode($\"data\").as(\"DATA1\") )\n",
    "//babyname2.printSchema()\n",
    "//babyname2.show()\n",
    "\n",
    "val parsed_Names = babyname2.withColumn(\"sid\",$\"DATA1\"(0)).withColumn(\"id\",$\"DATA1\"(1)).withColumn(\"position\",$\"DATA1\"(2)).withColumn(\"created_at\",$\"DATA1\"(3)).withColumn(\"created_meta\",$\"DATA1\"(4)).withColumn(\"updated_at\",$\"DATA1\"(5)).withColumn(\"updated_meta\",$\"DATA1\"(6)).withColumn(\"meta\",$\"DATA1\"(7)).withColumn(\"Year\",$\"DATA1\"(8)).withColumn(\"first_name\",$\"DATA1\"(9)).withColumn(\"county\",$\"DATA1\"(10)).withColumn(\"sex\",$\"DATA1\"(11)).withColumn(\"count\",$\"DATA1\"(12)).select(\"sid\",\"id\", \"position\", \"created_at\", \"created_meta\", \"updated_at\", \"updated_meta\", \"meta\", \"year\", \"first_name\", \"county\", \"sex\", \"count\")\n",
    "//parsed_Names.show(1)\n",
    "parsed_Names.createOrReplaceTempView(\"babyname3\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4672b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "//parsed_Names.groupBy(\"year\",\"first name\").count().orderBy(asc(\"year\"),desc(\"count\")).show\n",
    "\n",
    "val Pupular_Names = spark.sql(\"select year, first_name from (select year, first_name, count(*) as cnt,row_number() over (partition by year order by count(*) desc) as seqnum from babyname3 group by year, first_name) yn where seqnum = 1 order by year desc\")\n",
    "Pupular_Names.show()\n",
    "\n",
    "//val babydf3 = spark.sql(\"SELECT first_name, count(first_name) as Max_Count, year FROM babyname3 group by year, First_Name order by year desc, count(First_Name) desc\")\n",
    "//babydf3.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56114bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
