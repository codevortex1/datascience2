{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a3b40f2-f236-4f1a-ad18-68848056f114",
   "metadata": {},
   "source": [
    "Create Dataset examples and joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6692814-7971-4b12-8683-84b3b9039cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "val numseq = Seq(1,2,3,4,5)\n",
    "val numds = numseq.toDS()\n",
    "numds.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "93f34eb6-0706-4a1a-98f0-788b183082ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+------+------+-------+-------+\n",
      "| id| name|deptno|deptno|  dname|   dloc|\n",
      "+---+-----+------+------+-------+-------+\n",
      "|  1| PAUL|    10|    10|FINANCE| BOSTON|\n",
      "|  2|LAURA|    10|    10|FINANCE| BOSTON|\n",
      "|  3|  SAM|    20|    20|     HR| DALLAS|\n",
      "|  4|  JAY|    20|    20|     HR| DALLAS|\n",
      "|  5| KATE|    30|    30|  SALES|CHICAGO|\n",
      "|  6|  JOE|    30|    30|  SALES|CHICAGO|\n",
      "+---+-----+------+------+-------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "defined class emp\n",
       "empseq: Seq[emp] = List(emp(1,PAUL,10), emp(2,LAURA,10), emp(3,SAM,20), emp(4,JAY,20), emp(5,KATE,30), emp(6,JOE,30))\n",
       "empds: org.apache.spark.sql.Dataset[emp] = [id: int, name: string ... 1 more field]\n",
       "defined class dept\n",
       "deptseq: Seq[dept] = List(dept(10,FINANCE,BOSTON), dept(20,HR,DALLAS), dept(30,SALES,CHICAGO), dept(40,MARKETING,DENVER))\n",
       "deptds: org.apache.spark.sql.Dataset[dept] = [deptno: int, dname: string ... 1 more field]\n",
       "matchdf: org.apache.spark.sql.DataFrame = [id: int, name: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case class emp(id:Int , name:String,deptno:Int)\n",
    "val empseq = Seq(emp(1,\"PAUL\",10),emp(2,\"LAURA\",10),emp(3,\"SAM\",20),emp(4,\"JAY\",20),emp(5,\"KATE\",30),emp(6,\"JOE\",30))\n",
    "val empds = empseq.toDS()\n",
    "case class dept(deptno:Int , dname:String,dloc:String)\n",
    "val deptseq = Seq(dept(10,\"FINANCE\",\"BOSTON\"),dept(20,\"HR\",\"DALLAS\"),dept(30,\"SALES\",\"CHICAGO\"),dept(40,\"MARKETING\",\"DENVER\"))\n",
    "val deptds = deptseq.toDS()\n",
    "//empds.show()\n",
    "//deptds.show()\n",
    "val matchdf = empds.join(deptds, empds(\"deptno\") === deptds(\"deptno\"))\n",
    "matchdf.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b356639c-4289-4e3f-83e8-476f90c16c69",
   "metadata": {},
   "source": [
    "#Sql based join by convertingthe ds to temp tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b54fb274-87fe-4617-b8b1-faa53dac9abd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+---------+---------+----------------------------+\n",
      "|matchId|   player1|  player2|birthYear|birthYear|abs((birthYear - birthYear))|\n",
      "+-------+----------+---------+---------+---------+----------------------------+\n",
      "|      1|John Wayne| John Doe|     1986|     1995|                           9|\n",
      "|      2|  Ive Fish|San Simon|     1990|     1974|                          16|\n",
      "+-------+----------+---------+---------+---------+----------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sqlContext: org.apache.spark.sql.SQLContext = org.apache.spark.sql.SQLContext@63821fde\n",
       "defined class Match\n",
       "defined class Player\n",
       "matches: Seq[Match] = List(Match(1,John Wayne,John Doe), Match(2,Ive Fish,San Simon))\n",
       "players: Seq[Player] = List(Player(John Wayne,1986), Player(Ive Fish,1990), Player(San Simon,1974), Player(John Doe,1995))\n",
       "matchesDf: org.apache.spark.sql.DataFrame = [matchId: int, player1: string ... 1 more field]\n",
       "playersDf: org.apache.spark.sql.DataFrame = [name: string, birthYear: int]\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sqlContext = new org.apache.spark.sql.SQLContext(sc)\n",
    "\n",
    "case class Match(matchId: Int, player1: String, player2: String)\n",
    "case class Player(name: String, birthYear: Int)\n",
    "\n",
    "val matches = Seq(\n",
    "  Match(1, \"John Wayne\", \"John Doe\"),\n",
    "  Match(2, \"Ive Fish\", \"San Simon\")\n",
    ")\n",
    "\n",
    "val players = Seq(\n",
    "  Player(\"John Wayne\", 1986),\n",
    "  Player(\"Ive Fish\", 1990),\n",
    "  Player(\"San Simon\", 1974),\n",
    "  Player(\"John Doe\", 1995)\n",
    ")\n",
    "\n",
    "val matchesDf = sqlContext.createDataFrame(matches)\n",
    "val playersDf = sqlContext.createDataFrame(players)\n",
    "\n",
    "matchesDf.registerTempTable(\"matches\")\n",
    "playersDf.registerTempTable(\"players\")\n",
    "\n",
    "sqlContext.sql(\n",
    "  \"select matchId, player1, player2, p1.birthYear, p2.birthYear, abs(p1.birthYear-p2.birthYear) \" +\n",
    "  \"from matches m inner join  players p1 inner join players p2 \" +\n",
    "  \"where m.player1 = p1.name and m.player2 = p2.name\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deeb5ccf-b6af-4642-8b76-76cdec0517bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
